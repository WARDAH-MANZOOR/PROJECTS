{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5dh_2H2MtpK"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.models.detection as models_detection\n",
        "import torchvision.transforms as transforms\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the pre-trained object detection model (e.g., YOLO or Faster R-CNN)\n",
        "model = models_detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Create a function to preprocess image frames\n",
        "def preprocess_image(frame):\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    return transform(frame).unsqueeze(0)\n",
        "\n",
        "# Initialize video capture\n",
        "cap = cv2.VideoCapture('video.mp4')\n",
        "\n",
        "# Initialize object tracker (e.g., using OpenCV's built-in tracker)\n",
        "tracker = cv2.TrackerKCF_create()\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Preprocess the frame\n",
        "    input_tensor = preprocess_image(frame)\n",
        "\n",
        "    # Run object detection\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "\n",
        "    # Extract bounding boxes and labels\n",
        "    boxes = output[0]['boxes'].numpy()\n",
        "    labels = output[0]['labels'].numpy()\n",
        "\n",
        "    for box, label in zip(boxes, labels):\n",
        "        x, y, w, h = map(int, box)\n",
        "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f'Label: {label}', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    # Display the frame with bounding boxes\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "    # Press 'q' to exit\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release video capture and close windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oq5nKbzlNFKe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}